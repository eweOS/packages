diff --git a/src/modules/video_coding/codecs/h264/h264_decoder_impl.cc b/src/modules/video_coding/codecs/h264/h264_decoder_impl.cc
index 76d04e41..bc3917c5 100644
--- a/src/modules/video_coding/codecs/h264/h264_decoder_impl.cc
+++ b/src/modules/video_coding/codecs/h264/h264_decoder_impl.cc
@@ -14,6 +14,9 @@
 // #ifdef unless needed and tested.
 #ifdef WEBRTC_USE_H264
 
+#define HAVE_FFMPEG_REORDERED_OPAQUE (LIBAVFORMAT_VERSION_INT < \
+                                      AV_VERSION_INT(59, 8, 100))
+
 #include "modules/video_coding/codecs/h264/h264_decoder_impl.h"
 
 #include <algorithm>
@@ -212,7 +215,9 @@ int H264DecoderImpl::AVGetBuffer2(AVCodecContext* context,
   int total_size = y_size + 2 * uv_size;
 
   av_frame->format = context->pix_fmt;
+#if HAVE_FFMPEG_REORDERED_OPAQUE
   av_frame->reordered_opaque = context->reordered_opaque;
+#endif
 
   // Create a VideoFrame object, to keep a reference to the buffer.
   // TODO(nisse): The VideoFrame's timestamp and rotation info is not used.
@@ -361,7 +366,9 @@ int32_t H264DecoderImpl::Decode(const EncodedImage& input_image,
   }
   packet->size = static_cast<int>(input_image.size());
   int64_t frame_timestamp_us = input_image.ntp_time_ms_ * 1000;  // ms -> Î¼s
+#if HAVE_FFMPEG_REORDERED_OPAQUE
   av_context_->reordered_opaque = frame_timestamp_us;
+#endif
 
   int result = avcodec_send_packet(av_context_.get(), packet.get());
 
@@ -378,9 +385,11 @@ int32_t H264DecoderImpl::Decode(const EncodedImage& input_image,
     return WEBRTC_VIDEO_CODEC_ERROR;
   }
 
+#if HAVE_FFMPEG_REORDERED_OPAQUE
   // We don't expect reordering. Decoded frame timestamp should match
   // the input one.
   RTC_DCHECK_EQ(av_frame_->reordered_opaque, frame_timestamp_us);
+#endif
 
   // TODO(sakal): Maybe it is possible to get QP directly from FFmpeg.
   h264_bitstream_parser_.ParseBitstream(input_image);
